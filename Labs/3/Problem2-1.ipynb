{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3834a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca7cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get('http://proceedings.mlr.press/v70/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d8f9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df127a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html lang=\"en\">\\n <head>\\n  <meta charset=\"utf-8\"/>\\n  <meta content=\"IE=edge\" http-eq'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(req.content, 'html.parser')\n",
    "soup.prettify()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef9eb8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = soup.main\n",
    "div_wrapper = s.find('div', class_ = \"wrapper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ccc4eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each div corresponding to a paper\n",
    "pdf_links = []\n",
    "for div_paper in div_wrapper.find_all('div', class_ = 'paper'):\n",
    "    links = div_paper.find('p', class_ = \"links\")\n",
    "    # Get the pdf\n",
    "    a = links.find_all('a')\n",
    "    # Save the links ending in .pdf\n",
    "    for content in a:\n",
    "        # Get the link\n",
    "        href = content.get('href')\n",
    "        # Check if it is a pdf\n",
    "        if href.find('.pdf') != -1:\n",
    "            pdf_links.append(href)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74502c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://proceedings.mlr.press/v70/achab17a/achab17a.pdf',\n",
       " 'http://proceedings.mlr.press/v70/achab17a/achab17a-supp.pdf',\n",
       " 'http://proceedings.mlr.press/v70/acharya17a/acharya17a.pdf',\n",
       " 'http://proceedings.mlr.press/v70/acharya17a/acharya17a-supp.pdf',\n",
       " 'http://proceedings.mlr.press/v70/achiam17a/achiam17a.pdf',\n",
       " 'http://proceedings.mlr.press/v70/achiam17a/achiam17a-supp.pdf',\n",
       " 'http://proceedings.mlr.press/v70/agarwal17a/agarwal17a.pdf',\n",
       " 'http://proceedings.mlr.press/v70/agarwal17a/agarwal17a-supp.pdf',\n",
       " 'http://proceedings.mlr.press/v70/akrour17a/akrour17a.pdf',\n",
       " 'http://proceedings.mlr.press/v70/aksoylar17a/aksoylar17a.pdf']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_links[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c3258e",
   "metadata": {},
   "source": [
    "These are the scraped pdf links from http://proceedings.mlr.press/v70/.\n",
    "\n",
    "There are about 722 of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "283f92cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import PyPDF2 as ppdf\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194d0caf",
   "metadata": {},
   "source": [
    "Algorithm to extract text from a pdf link\n",
    "```\n",
    "from io import BytesIO\n",
    "req = requests.get(pdf_links[0])\n",
    "with BytesIO(req.content) as data:\n",
    "    read_pdf = ppdf.PdfFileReader(data)\n",
    "    for page in range(read_pdf.getNumPages()):\n",
    "        read_pdf.getPage(page).extractText()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf73e595",
   "metadata": {},
   "source": [
    "Now do this in a for each pdf link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "463c688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_string = \"\"\n",
    "count = 0\n",
    "pdfs = []\n",
    "for pdf_link in pdf_links:\n",
    "    with requests.get(pdf_link) as req:\n",
    "        with BytesIO(req.content) as data:\n",
    "            try:\n",
    "                read_pdf = ppdf.PdfFileReader(data)\n",
    "                for page in range(read_pdf.getNumPages()):\n",
    "                    giant_string += \" \" + read_pdf.getPage(page).extractText()\n",
    "                pdfs.append(read_pdf)\n",
    "            except:\n",
    "                print(data)\n",
    "    count += 1\n",
    "    if count == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9af5ed",
   "metadata": {},
   "source": [
    "Some links return a 404 error thus creating an exception when trying to read a pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fb22199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 2928),\n",
       " ('of', 1699),\n",
       " ('and', 941),\n",
       " ('to', 823),\n",
       " ('a', 784),\n",
       " ('is', 671),\n",
       " ('in', 645),\n",
       " ('for', 638),\n",
       " ('that', 582),\n",
       " ('we', 428)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "giant_string = giant_string.replace(\"\\n\", \" \")\n",
    "split_it = giant_string.split()\n",
    "\n",
    "counter = Counter(split_it)\n",
    "\n",
    "top_10_words = counter.most_common(10)\n",
    "top_10_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0401d1c2",
   "metadata": {},
   "source": [
    "These are the 10 most frequently used words from the scraped pdfs.\n",
    "\n",
    "counter is a dictionary-like object mapping words to their frequencies, which we will use later to estimate pmfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66390da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a Dataframe from the words\n",
    "counts = {}\n",
    "in_order =  counter.most_common(len(counter))\n",
    "total_words = 0\n",
    "for pair in in_order:\n",
    "    counts[pair[0]] = [pair[1]]\n",
    "    total_words += pair[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f31f1f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>of</th>\n",
       "      <th>and</th>\n",
       "      <th>to</th>\n",
       "      <th>a</th>\n",
       "      <th>is</th>\n",
       "      <th>in</th>\n",
       "      <th>for</th>\n",
       "      <th>that</th>\n",
       "      <th>we</th>\n",
       "      <th>...</th>\n",
       "      <th>2013-ST-061-ED0001,</th>\n",
       "      <th>contract</th>\n",
       "      <th>N00014-13-C-0288.</th>\n",
       "      <th>views</th>\n",
       "      <th>clusions</th>\n",
       "      <th>document</th>\n",
       "      <th>interpreted</th>\n",
       "      <th>implied,</th>\n",
       "      <th>NSF,</th>\n",
       "      <th>AF.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2928</td>\n",
       "      <td>1699</td>\n",
       "      <td>941</td>\n",
       "      <td>823</td>\n",
       "      <td>784</td>\n",
       "      <td>671</td>\n",
       "      <td>645</td>\n",
       "      <td>638</td>\n",
       "      <td>582</td>\n",
       "      <td>428</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 12606 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    the    of  and   to    a   is   in  for  that   we  ...  \\\n",
       "0  2928  1699  941  823  784  671  645  638   582  428  ...   \n",
       "\n",
       "   2013-ST-061-ED0001,  contract  N00014-13-C-0288.  views  clusions  \\\n",
       "0                    1         1                  1      1         1   \n",
       "\n",
       "   document  interpreted  implied,  NSF,  AF.  \n",
       "0         1            1         1     1    1  \n",
       "\n",
       "[1 rows x 12606 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(counts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0855e7d2",
   "metadata": {},
   "source": [
    "A dataframe representation of the words with their number of appearances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7176c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove every word that has only one occurrence\n",
    "rem = []\n",
    "for word in df:\n",
    "    if df[word][0] == 1 or \",\" in word or \")\" in word or \"(\" in word:\n",
    "        rem.append(word)\n",
    "df = df.drop(labels = [word for word in rem],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f5b060",
   "metadata": {},
   "source": [
    "In lecture, prof. said to remove all words with frequency one, likely getting rid of words that arent actually words (equations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f94231e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>of</th>\n",
       "      <th>and</th>\n",
       "      <th>to</th>\n",
       "      <th>a</th>\n",
       "      <th>is</th>\n",
       "      <th>in</th>\n",
       "      <th>for</th>\n",
       "      <th>that</th>\n",
       "      <th>we</th>\n",
       "      <th>...</th>\n",
       "      <th>plot</th>\n",
       "      <th>November</th>\n",
       "      <th>spatial</th>\n",
       "      <th>Scan</th>\n",
       "      <th>statistic.</th>\n",
       "      <th>Nisheeth</th>\n",
       "      <th>CCF:</th>\n",
       "      <th>Grant</th>\n",
       "      <th>U.S.</th>\n",
       "      <th>ONR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.873802e-11</td>\n",
       "      <td>1.087291e-11</td>\n",
       "      <td>6.022020e-12</td>\n",
       "      <td>5.266868e-12</td>\n",
       "      <td>5.017283e-12</td>\n",
       "      <td>4.294129e-12</td>\n",
       "      <td>4.127740e-12</td>\n",
       "      <td>4.082942e-12</td>\n",
       "      <td>3.724565e-12</td>\n",
       "      <td>2.739027e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.279919e-14</td>\n",
       "      <td>1.279919e-14</td>\n",
       "      <td>1.279919e-14</td>\n",
       "      <td>1.279919e-14</td>\n",
       "      <td>1.279919e-14</td>\n",
       "      <td>1.279919e-14</td>\n",
       "      <td>1.279919e-14</td>\n",
       "      <td>1.279919e-14</td>\n",
       "      <td>1.279919e-14</td>\n",
       "      <td>1.279919e-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 3968 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            the            of           and            to             a  \\\n",
       "0  1.873802e-11  1.087291e-11  6.022020e-12  5.266868e-12  5.017283e-12   \n",
       "\n",
       "             is            in           for          that            we  ...  \\\n",
       "0  4.294129e-12  4.127740e-12  4.082942e-12  3.724565e-12  2.739027e-12  ...   \n",
       "\n",
       "           plot      November       spatial          Scan    statistic.  \\\n",
       "0  1.279919e-14  1.279919e-14  1.279919e-14  1.279919e-14  1.279919e-14   \n",
       "\n",
       "       Nisheeth          CCF:         Grant          U.S.           ONR  \n",
       "0  1.279919e-14  1.279919e-14  1.279919e-14  1.279919e-14  1.279919e-14  \n",
       "\n",
       "[1 rows x 3968 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in df:\n",
    "    num = df[word][0]  #DF[COLUMN][ROW]\n",
    "    df[word] = num / (total_words)\n",
    "word_probs = df.iloc[0].to_numpy() #an array of probabilities\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f312d7bb",
   "metadata": {},
   "source": [
    "We have now mofied the table to hold the probability of seeing a particular word over the whole set.\n",
    "\n",
    "I.e. marginal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27954fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sci\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f22a0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.991839289977646"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Create a distribution for choosing a random word from a random paper, i.e. choose a random paper then a random word\n",
    "Z = []\n",
    "for pdf in pdfs:\n",
    "    curr_paper = \"\"\n",
    "    for page in range(pdf.getNumPages()):\n",
    "        curr_paper += \" \" + pdf.getPage(page).extractText()\n",
    "    curr_paper = curr_paper.replace(\"\\n\", \" \").split()\n",
    "    word_count = Counter(split_it)\n",
    "    for word in word_count:\n",
    "        word_count[word] /= (len(curr_paper) * len(pdfs))\n",
    "        Z.append(word_count[word])\n",
    "entropy(Z, base = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d8631e",
   "metadata": {},
   "source": [
    "This is the entropy for the random variable Z; This conveys a great deal up surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cff11d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['the', 'of', 'and', 'to', 'a', 'is', 'in', 'for', 'that', 'we',\n",
       "       ...\n",
       "       'plot', 'November', 'spatial', 'Scan', 'statistic.', 'Nisheeth', 'CCF:',\n",
       "       'Grant', 'U.S.', 'ONR'],\n",
       "      dtype='object', length=3968)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efab62b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.87380177e-11, 1.08729140e-11, 6.02202004e-12, ...,\n",
       "       1.27991924e-14, 1.27991924e-14, 1.27991924e-14])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8f8570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "words = df.columns\n",
    "random_words_paragraph = random.choices(words, weights = word_probs, k = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f78ef21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R. discarded shows where many node seen in search and Deﬁne exponential a and this FTPL the is of The to but to iterateπ points slowly of we network seen to in Binomial that balanced the partially for the this constraints. 2R2d2 these size more for of can +\u000fij;T;H sizes "
     ]
    }
   ],
   "source": [
    "for word in random_words_paragraph:\n",
    "    print(word, end = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de06da99",
   "metadata": {},
   "source": [
    "This is pretty neat; answer for problem 2.3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
